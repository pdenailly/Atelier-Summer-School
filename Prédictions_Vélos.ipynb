{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+keYE5wH3JM/Yp1YQnBM4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pdenailly/Atelier-Summer-School/blob/main/Pr%C3%A9dictions_V%C3%A9los.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Atelier prédictions probabilistes de séries multivariées avec la librairie GluonTS**"
      ],
      "metadata": {
        "id": "WNELFySes4R4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bienvenu dans cet atelier ! Nous allons y explorer quelques modèles de réseaux de neurone récurrents pour la prédiction probabiliste de séries temporelles multivariées et potentiellement corrélées. \n",
        "\n",
        "Pour ce cas pratique nous nous intéresserons à des séries temporelles de traffic de vélo, comptés à chaque heure entre janvier et juin 2022 en plusieurs points de la ville de Paris.\n",
        "\n",
        "Dans ce travail nous travaillerons avec la librairie *GluonTS* qui encapsule des modèles de prédiction probabiliste construits avec les librairies *MXNET* ou *Pytorch*. \n",
        "\n"
      ],
      "metadata": {
        "id": "jkgfEYHLmokT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation des librairies"
      ],
      "metadata": {
        "id": "a9KlZks5NpGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation de la librairie GluonTS."
      ],
      "metadata": {
        "id": "TVTkBUOKI3GN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tBxDNiUHEVh"
      },
      "outputs": [],
      "source": [
        "! pip install gluonts['mxnet']\n",
        "! pip install matplotlib\n",
        "! pip install orjson"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importation des librairies nécessaires\n"
      ],
      "metadata": {
        "id": "B4CnhtFfN03D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons commencer par importer toutes les librairies nécessaires à cet atelier. Assurez vous que le fichier python *rolling_dataset* est bien présent dans votre répertoire courant. Il s'agit d'un ensemble de fonctions qui nous seront utiles pour créer une fenêtre gliassante sur la base de test."
      ],
      "metadata": {
        "id": "Dnu5gmcVc3Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Traitement des données\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import orjson\n",
        "\n",
        "#Visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#Distributions et modèles disponibles\n",
        "from gluonts.mx.trainer import Trainer\n",
        "\n",
        "#Pour l'importation des données\n",
        "from gluonts.dataset.repository.datasets import get_dataset\n",
        "from rolling_dataset import (  #Cette fonction a disparu dans la derniÃ¨re version de GluonTS\n",
        "    StepStrategy,\n",
        "    generate_rolling_dataset,\n",
        ")\n",
        "from gluonts.dataset.common import ListDataset\n",
        "\n",
        "\n",
        "#Les modèles DeepVAR\n",
        "from gluonts.mx.model.deepvar import DeepVAREstimator\n",
        "from gluonts.mx.distribution.lowrank_multivariate_gaussian import LowrankMultivariateGaussianOutput\n",
        "from gluonts.mx.distribution.multivariate_gaussian import MultivariateGaussianOutput\n",
        "\n",
        "#Les modèles GPVAR\n",
        "from gluonts.mx.model.gpvar import GPVAREstimator\n",
        "from gluonts.mx.distribution.lowrank_gp import LowrankGPOutput\n",
        "\n",
        "#Fonctions de prédiction et d'évaluation\n",
        "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
        "from gluonts.evaluation import MultivariateEvaluator, Evaluator"
      ],
      "metadata": {
        "id": "Md6mp8MwN-Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importation des données de comptages vélos"
      ],
      "metadata": {
        "id": "l9qiXtwBOTZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les données de comptages vélos sont disponibles en open source à l'adresse suivant : https://opendata.paris.fr/explore/dataset/comptage-velo-historique-donnees-compteurs. Il s'agit de données issues de comptages en différents emplacements de la ville de Paris à chaque heure. \n",
        "\n",
        "De cette base de données nous avons conservé 80 lieux de comptages de la ville de Paris (sans valeurs manquantes) : elles se trouvent dans le fichier 'bike_data.csv'. Assurez-vous que le fichier ait bien été importé dans le répertoire courant. Si vous rangez le fichier dans un autre répertoire, assurez vous de spécifier le chemin correct dans la fonction *read_csv* de pandas. \n",
        "\n",
        "Nous prendrons comme base d'entraînement la période de janvier à fin mai 2022 (soit une matrice 3575x80). 30 fenêtres glissantes seront utilisées en test pour couvrir l'ensemble du mois de juin 2022 (avec 24 tranches horaires de prédites à chaque fenêtre)."
      ],
      "metadata": {
        "id": "APMqmmsJpH0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importation des données de comptage vélos depuis le fichier .csv\n",
        "bike_data = pd.read_csv('bike_data.csv', sep=\",\", index_col=1, parse_dates=True, decimal='.').iloc[: , 1:]  \n",
        "\n",
        "#Base d'entrainement\n",
        "bike_data_train = bike_data[:pd.Timestamp('2022-05-31 23:00:00', freq='H')]\n",
        "bike_data_train = bike_data_train.transpose()\n",
        "\n",
        "#La base de test contient les comptages d'un mois supplémentaire - non utilisé dans l'apprentissage\n",
        "bike_data_test = bike_data\n",
        "bike_data_test = bike_data_test.transpose()"
      ],
      "metadata": {
        "id": "hOZ2WO1COZSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant il s'agit de mettre ces données sous un format compréhensible par la librairie GluonTS que nous utiliserons dans cet atelier. Vous n'avez pas besoin de comprendre dans le détail ce code, juste que GluonTS a besoin de données comprenant des balises particulières 'target', 'start', etc.. Ce format permet aux différentes fonctions d'entraînement et d'évaluation d'aller chercher les bonnes informations dans les données. \n",
        "\n",
        "Nous transformons également la base de test en un objet itérable. Le but est de pouvoir faire des prédictions sur plusieurs fenêtres afin de pouvoir couvrir tout le mois de Juin. Nous ilustrerons ces fenêtres ultérieurement."
      ],
      "metadata": {
        "id": "0VQOYGaOsTph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Données mises sous la forme d'objets ListDataset, compréhensibles par GluonTS \n",
        "train_ds = ListDataset([{\"start\": pd.Timestamp('2022-01-03 00:00:00', freq='H'), \"target\": bike_data_train}], freq='H', one_dim_target=False)\n",
        "test_ds = ListDataset([{\"start\": pd.Timestamp('2022-01-03 00:00:00', freq='H'), \"target\": bike_data_test}], freq='H', one_dim_target=False)\n",
        "\n",
        "#Mise en place d'une stratégie permettant de subdiviser la base de test en plusieurs fenêtres à prédire (tailles 24)        \n",
        "strategy=StepStrategy(\n",
        "      prediction_length=24,\n",
        "      step_size=24\n",
        " )\n",
        " \n",
        "#Cette liste intègrera l'ensemble des fenêtres de test à prédire\n",
        "ds = []\n",
        "\n",
        "#Récupération de la base de test, à convertir en df\n",
        "item = (next(iter(test_ds)))\n",
        "target = item[\"target\"]\n",
        "start = item[\"start\"]\n",
        "index = pd.date_range(start=str(start), periods=target.shape[1], freq='H')\n",
        "series = pd.DataFrame(target.T, index=index)\n",
        "\n",
        "prediction_window = series\n",
        "nb_j = 0\n",
        "         \n",
        "for window in strategy.get_windows(prediction_window):\n",
        "    nb_j = nb_j + 1\n",
        "    new_item = item.copy()\n",
        "    new_item['target'] = np.concatenate(\n",
        "        [window.to_numpy()]\n",
        "      ).T\n",
        "    ds.append(new_item)\n",
        "    if nb_j > 29:\n",
        "      break\n",
        "  \n",
        "test_ds = ds\n",
        "target_dim=int(test_ds[1]['target'].shape[0])\n",
        "freq='H'\n",
        "prediction_length = 24"
      ],
      "metadata": {
        "id": "A7sj-B3qs1x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant que nos données d'entrainement (train_ds) et de d'évaluation (test_ds) ont été crées, nous pouvons les visualiser un peu. Pour commencer voyons quelques informations à leur propos."
      ],
      "metadata": {
        "id": "ijhMff5XwpZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Longueur d'une fenêtre de prédiction dans la base de test': {prediction_length}\")\n",
        "print(f\"Fréquence des séries temporelles: {freq}\")\n",
        "print(f\"Nombre de séries temporelles: {target_dim}\")\n",
        "print(f\"Nombre de fenêtres glissantes dans la base de test: {len(test_ds)}\")\n",
        "print(f\"Nombre d'heures dans la base d'entrainement: {(train_ds[0]['target'].shape[1])}\")\n",
        "print(f\"Nombre total d'heures dans la base de test: {(test_ds[0]['target'].shape[1]) - (train_ds[0]['target'].shape[1])}\")"
      ],
      "metadata": {
        "id": "q5yTB5UFw-vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons également visualiser quelques séries de comptages. Par exemple regardons les 5 premières séries sur la première semaine de la base d'entraînement. Vous pouvez modifier ici avec le nombre de séries (n_series) et le nombre de jours (n_jours)."
      ],
      "metadata": {
        "id": "d9Zh0TxbyCwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Elicitation du nombre de séries et du nombre de jours que l'on souhaite visualiser (MODIFIABLE)\n",
        "n_jours = 7\n",
        "n_series = 5\n",
        "\n",
        "##On remet en forme les données sous forme de dataframes pour la visualisation\n",
        "\n",
        "#Entrainement\n",
        "target = train_ds[0]['target'].T\n",
        "start = train_ds[0]['start']\n",
        "periods = target.shape[0]\n",
        "index = pd.date_range(start=start.strftime('%Y-%m-%d %H:%M:%S'), periods=periods, freq=start.freq)\n",
        "series_train = pd.DataFrame(target, index=index)\n",
        "\n",
        "#Test\n",
        "target = test_ds[0]['target'].T\n",
        "start = test_ds[0]['start']\n",
        "periods = target.shape[0]\n",
        "index = pd.date_range(start=start.strftime('%Y-%m-%d %H:%M:%S'), periods=periods, freq=start.freq)\n",
        "series_test = pd.DataFrame(target, index=index)\n",
        "\n",
        "##Création des subplots dans lesquels seront représentés les graphiques\n",
        "label_prefix = \"\"\n",
        "rows = n_series\n",
        "cols = 1\n",
        "fig, axs = plt.subplots(rows, cols, figsize=(24, 24))\n",
        "fig.suptitle('Comptages de vélos, sur quelques jours de la base d\\'entrainement', fontsize=40)\n",
        "axx = axs\n",
        "                  \n",
        "for dim in range(0, int((rows*cols))):\n",
        "    ax = axx[dim]\n",
        "    ax.grid(which=\"both\")\n",
        "    series_train[:(n_jours)*prediction_length][dim].plot(ax=ax, color = 'grey') "
      ],
      "metadata": {
        "id": "lLhkorP5yYGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous remarquons deux éléments sur ces séries :\n",
        "\n",
        "\n",
        "1.   Les jours de semaine et les jours de weekend ont des profils bien différents. Les jours de semaine présentent ainsi des pics de fréquentation que l'on ne voit pas le weekend.\n",
        "2.   Ces pics de fréquentation peuvent se trouver le matin pour certains capteurs, ou le soir pour d'autres. Ce phénomène doit provenir directement de la situation des capteurs dans la ville : certains proches des zones de fort passage le matin, d'autres proches des zones de fort passage le soir.\n",
        "\n",
        "Nous pouvons également visualiser quelques fenêtres glissantes pour nous faire une idée des différentes fréquentations que l'on aura à prédire. Là encore vous pouvez modifier le nombre de séries que vous souhaitez visualiser (n_series).\n"
      ],
      "metadata": {
        "id": "CeW33esr0DHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Nombre de séries que l'on visualisera\n",
        "n_series = 5\n",
        "\n",
        "label_prefix = \"\"\n",
        "rows = n_series\n",
        "cols = 4\n",
        "fig, axs = plt.subplots(rows, cols, figsize=(24, 24), sharex=True, sharey=True)\n",
        "\n",
        "fig.supxlabel('Fenêtres glissantes', fontsize=25)\n",
        "fig.supylabel('Séries de comptages', fontsize=25)\n",
        "\n",
        "fig.suptitle('Exemple de fenêtres glissantes pour plusieurs séries de comptages', fontsize=40)\n",
        "axx = axs\n",
        "\n",
        "                  \n",
        "for dim in range(0, rows):\n",
        "    ax3 = axx[dim, 3]\n",
        "    series_test[-(6*prediction_length):-(4*prediction_length)][dim].plot(ax=ax3, color = 'blue')\n",
        "    series_test[-(6*prediction_length):-(3*prediction_length)][dim].plot(ax=ax3, color = 'blue', linestyle='dashed')\n",
        "    ax3.axvline(series_test.index[-(4*prediction_length)], color=\"r\")\n",
        "    \n",
        "    ax2 = axx[dim, 2]\n",
        "    series_test[-(6*prediction_length):-(3*prediction_length)][dim].plot(ax=ax2, color = 'blue')\n",
        "    series_test[-(6*prediction_length):-(2*prediction_length)][dim].plot(ax=ax2, color = 'blue', linestyle='dashed')\n",
        "    ax2.axvline(series_test.index[-(3*prediction_length)], color=\"r\")\n",
        "    \n",
        "    ax1 = axx[dim, 1]\n",
        "    series_test[-(6*prediction_length):-(2*prediction_length)][dim].plot(ax=ax1, color = 'blue')\n",
        "    series_test[-(2*prediction_length):-prediction_length][dim].plot(ax=ax1, color = 'blue', linestyle='dashed')\n",
        "    ax1.axvline(series_test.index[-(2*prediction_length)], color=\"r\")\n",
        "    \n",
        "    ax0 = axx[dim, 0]\n",
        "    series_test[-(6*prediction_length):-prediction_length][dim].plot(ax=ax0, color = 'blue')\n",
        "    series_test[-prediction_length:][dim].plot(ax=ax0, color = 'blue', linestyle='dashed')\n",
        "    ax0.axvline(series_test.index[-prediction_length], color=\"r\")"
      ],
      "metadata": {
        "id": "t3n9f6Qd1Wcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette figure montre un exemple de 4 fenêtres glissantes, visualisées pour *n_series* séries de comptages. On prédit par exemple la dernière journée de juin, puis le 29 juin, puis le 28, ...\n",
        "\n",
        "Nous allons maintenant passer à l'application de modèles de prédiction probabilistes sur ces données ! Les modèles sont ceux que nous avons vu dans la présentation (référez vous à la table récapitulative des modèles). Tous les modèles sont des réseaux de neurone récurrents avec une distribution en sortie pour de la prédiction probabiliste :\n",
        "* **Vec-lstm-fullrank-scaling** : intègre une distribution gaussienne avec une matrice de covariance pleine, et où les données en entrée sont mises à l'échelle par la moyenne.\n",
        "* **Vec-lstm-lowrank-copula** : intègre une distribution gaussienne de faible rang et transforme les données en entrée avec des copules gaussiennes.\n",
        "* **GP-copula** : applique un LSTM sur des sous groupes de séries avant de construire la distribution jointe avec une gaussienne de faible rang. Une transformation basée sur les copules est appliquée en entrée."
      ],
      "metadata": {
        "id": "iQa1fXuA1u3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entraînement d'un modèle de prédiction Vec-LSTM-fullrank-Scaling"
      ],
      "metadata": {
        "id": "X8wtpRF6ZqB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commençons avec notre premier modèle ! Pour commencer nous allons travailler avec un modèle Vec-lstm pour lequel il n'y a pas de transformation des données en entrée par Copules gaussiennes et qui n'utilise pas de matrice de faible rang. Les modèles Vec-lstm sont encodés sous la classe d'estimateurs *DeepVAR* sur *GluonTS*. \n",
        "\n",
        "Commençons par éliciter le modèle et ses différentes options. Nous allons choisir un entrainement sur 3 epochs avec 10 batches par epoch. Nous allons également spécifier un dropout à 0.01 et un taux d'apprentissage à 10-3. Nous utilisons des lags à 1, 2, 12 et 24 heures pour le modèle autorégressif."
      ],
      "metadata": {
        "id": "pmfsIPl7aIei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = DeepVAREstimator(\n",
        "            target_dim=target_dim,\n",
        "            dropout_rate=0.01,\n",
        "            prediction_length=prediction_length,\n",
        "            cell_type=\"lstm\",\n",
        "            lags_seq = [1, 12, 24],\n",
        "            conditioning_length = 50,\n",
        "            scaling=True,\n",
        "            freq=freq,\n",
        "            use_marginal_transformation=False,\n",
        "            distr_output=MultivariateGaussianOutput(dim = target_dim),\n",
        "            trainer=Trainer(\n",
        "         epochs=5,\n",
        "         learning_rate=1e-3,\n",
        "         num_batches_per_epoch=10),\n",
        "        )"
      ],
      "metadata": {
        "id": "OlsFs7Uea7nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une fois l'object \"estimator\" crée, nous pouvons lancer l'entraînement avec les options précisées. On va lancer sur 10 epochs, celui ci devrait aller assez vite."
      ],
      "metadata": {
        "id": "waG23KBhcZz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = estimator.train(train_ds)"
      ],
      "metadata": {
        "id": "182R8GBDHAkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voilà le modèle a été entraîné comme il faut. Vous constaterez que la loss (la -log vraisemblance) a diminué à chaque epoch, ce qui souligne qu'un apprentissage a bien eu lieu. \n",
        "\n",
        "Maintenant nous voulons regarder quelques statistiques de prédiction sur la base de prédiction. Pour cela des métriques (CRPS, MAPE, etc..) peuvent être calculées et moyennées sur l'ensemble des fenêtres de la base de prédiction. Pour lancer les prédictions, on peut utiliser la commande *make_evaluation_prediction* de Gluonts, elle peut prendre quelques dizaines de secondes à quelques minutes selon la taille des données et le nombre de répétitions (échantillons de Monte-Carlo). Pour nous cela devrait aller assez vite. Nous allons spécifier que nous répétons 30 fois chaque prédictions pour calculer des quantiles de prédictions."
      ],
      "metadata": {
        "id": "qmiSmeMQc4yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prédictions sur fenêtres glissantes\n",
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "                test_ds, predictor=predictor, num_samples=30\n",
        "            )\n",
        "\n",
        "forecasts = list(forecast_it)\n",
        "targets = list(ts_it)"
      ],
      "metadata": {
        "id": "_X5xoIEleCiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assurons nous de la dimension des objets crées lors de la prédiction, par exemple sur la dernière fenêtre."
      ],
      "metadata": {
        "id": "GJo3xPstfnyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_entry = forecasts[-1]\n",
        "print(f\"Nombre de répétitions de prédictions: {forecast_entry.num_samples}\")\n",
        "print(f\"Dimension des prédictions pour la fenêtre: {forecast_entry.samples.shape}\")\n",
        "print(f\"Date de départ de la fenêtre: {forecast_entry.start_date}\")\n",
        "print(f\"Fréquence de la série temporelle: {forecast_entry.freq}\")"
      ],
      "metadata": {
        "id": "tKwN6gujfyi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour la fenêtre étudiée, vous remarquerez que la dimension correspond à (*num_samples* X *prediction_length* X *target_dim*), ce qui est attendu pour nous (30 prédictions de faites, par série et par heure).\n",
        "\n",
        "Calculons nos métriques d'évaluation maintenant.\n",
        "Nous utilisons la classe *Evaluator* qui peut calculer des mesures de performance agrégées."
      ],
      "metadata": {
        "id": "0GG263Scer-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "evaluator = MultivariateEvaluator()\n",
        "\n",
        "agg_metric, item_metrics = evaluator(\n",
        "                    targets, forecasts, num_series=len(test_ds)\n",
        "                )\n",
        "\n",
        "print(\"CRPS: {}\".format(agg_metric['mean_wQuantileLoss']))\n",
        "print(\"MSE: {}\".format(agg_metric['MSE']))"
      ],
      "metadata": {
        "id": "4QuQ2SUbexGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notez bien les résultats des métriques CRPS et MSE que vous obtenez.\n",
        "Un certain nombre de paramètres, appelés hyperparamètres, sont inconnus a priori et il faut estimer plusieurs modèles avec différentes valeurs de ces hyperparamètres. On passe généralement par une grille de recherche (grid search) mais nous n'allons pas le faire ici. \n",
        "\n",
        "Plusieurs hyperparamètres peuvent être étudiés : le nombre de cellules de LSTM, le nombre de couches, le taux d'apprentissage, le nombre d'itérations d'apprentissage, etc.. Nous allons tester la modification d'un hyperparamètre et constater son effet sur les capacités de prédiction du modèle.\n",
        "\n",
        "A vous de jouer maintenant !\n",
        "Lancez l'apprentissage du même modèle DeepVAR précédent mais en considérant cette fois 3 couches pour le réseau de neurone récurrent (cherchez dans la documentation *gluonts.mx.model.deepvar* l'option dédiée et modifiez l'objet *estimator*, vous relancez ensuite l'apprentissage et l'évaluation sur la base de test). Que constatez vous ? Y a t-il une amélioration ou non des métriques calculées (CRPS, MSE) ? \n",
        "\n",
        "Une fois cette petite expérience effectuée nous allons étudier un autre modèle, potentiellement plus robuste."
      ],
      "metadata": {
        "id": "bbhGuHA5iADN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entraînement d'un modèle de prédiction Vec-LSTM-lowrank-Copula"
      ],
      "metadata": {
        "id": "sRue3JRViz9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons maintenant passer à un autre modèle : le *Vec-lstm-lowrank-Copula*. Vous allez construire l'estimateur pour ce modèle. Voici quelques indications :\n",
        "* Il s'agit d'un modèle Vec-lstm : utilisez la même classe *DeepVAREstimator* que pour le 1er modèle\n",
        "* Utilisez les options *scaling* et *use_marginal_transformation* pour gérer la transformation de vos données en entrée. Il s'agit de deux options de transformation, n'utilisez pas les deux ! (documentation dans https://ts.gluon.ai/stable/api/gluonts/gluonts.mx.model.deepvar.html)\n",
        "* Utilisez une distribution de sortie adaptée. Dans le premier modèle nous avions une distribution gaussienne avec matrice de covariance pleine (*MultivariateGaussianOutput*), ici nous souhaitons une distribution gaussienne avec matrice de faible rang en sortie. Cherchez la distribution adaptée dans la documentation : https://ts.gluon.ai/stable/api/gluonts/gluonts.mx.distribution.html (utilisez la liste des modules en bas de page). Choisissez un rang pour la matrice de covariance (une valeur petite, 5 par exemple, attention vous devez également préciser cette valeur de rang comme argument de *DeepVAREstimator*).\n",
        "* Enfin nous conserverons les mêmes valeurs d'hyperparamètres que dans le 1er modèle pour le réseau de neurone (nombre d'epochs, lags, dropout, etc.)."
      ],
      "metadata": {
        "id": "RDy6HF2LaQRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Construction de l'estimateur pour un modèle Vec-lstm-lowrank-copula\n",
        "\n",
        "estimator = DeepVAREstimator(\n",
        "            target_dim=target_dim,\n",
        "            dropout_rate=0.01,\n",
        "            prediction_length=prediction_length,\n",
        "            cell_type=\"lstm\",\n",
        "            lags_seq = [1, 2, 12, 24],\n",
        "            scaling=False,\n",
        "            freq=freq,\n",
        "            use_marginal_transformation=True,\n",
        "            rank = 5,\n",
        "            distr_output=LowrankMultivariateGaussianOutput(rank = 5, dim = target_dim),\n",
        "            trainer=Trainer(\n",
        "         epochs=10,\n",
        "         learning_rate=1e-3,\n",
        "         num_batches_per_epoch=10),\n",
        "        )\n",
        "\n",
        "\n",
        "#Entrainement sur la base d'apprentissage avec l'estimateur crée\n",
        "predictor = estimator.train(train_ds)\n"
      ],
      "metadata": {
        "id": "MVCJ5p0XQg4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si vous avez bien construit le modèle, vous devriez vous rendre compte que l'apprentissage est plus rapide. \n",
        "\n",
        "Le modèle a effectivement beaucoup moins de paramètres à apprendre dans le cas d'une matrice de covariance de faible rang par rapport à une matrice pleine. Vous devriez également constater qu'au bout de 5 epochs, la loss continue de décroitre beaucoup.\n",
        "\n",
        "Ce modèle est plus rapide mais est-il meilleur que le premier ? Lancez une prédiction sur les fenêtres de la base de test et calculez les métriques CRPS et MSE. Y a t-il eu une amélioration par rapport au modèle Vec-lstm-fullrank-scaling ? A votre avis pourquoi ?"
      ],
      "metadata": {
        "id": "0d_Q13wed5sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prédictions sur fenêtres glissantes\n",
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "                test_ds, predictor=predictor, num_samples=30\n",
        "            )\n",
        "\n",
        "forecasts = list(forecast_it)\n",
        "targets = list(ts_it)\n",
        "\n",
        "# Evaluation\n",
        "agg_metric, item_metrics = evaluator(\n",
        "                    targets, forecasts, num_series=len(test_ds)\n",
        "                )\n",
        "\n",
        "print(\"CRPS: {}\".format(agg_metric['mean_wQuantileLoss']))\n",
        "print(\"MSE: {}\".format(agg_metric['MSE']))\n"
      ],
      "metadata": {
        "id": "2gVWbNCcfTdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essayez de nouveau de lancer un entraînement avec ce modèle mais pour 10 epochs. Constatez vous une amélioration des métriques ?\n",
        "\n",
        "Maintenant nous pouvons visualiser les résultats de prédictions sur quelques fenêtres. La fonction ci-dessous permet de visualiser les profils observés et des enveloppes de prédiction que l'on peut préciser. Ces enveloppes de prédiction sont calculées à partir des quantiles des échantillons de séries prédites."
      ],
      "metadata": {
        "id": "sd7zaAHmgS-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(target, forecast, prediction_length, prediction_intervals=(50.0, 90.0), color='g', fname=None):\n",
        "    label_prefix = \"\"\n",
        "    rows = 3\n",
        "    cols = 4\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(24, 24))\n",
        "    axx = axs.ravel()\n",
        "    seq_len, target_dim = target.shape\n",
        "    \n",
        "    ps = [50.0] + [\n",
        "            50.0 + f * c / 2.0 for c in prediction_intervals for f in [-1.0, +1.0]\n",
        "        ]\n",
        "        \n",
        "    percentiles_sorted = sorted(set(ps))\n",
        "    \n",
        "    def alpha_for_percentile(p):\n",
        "        return (p / 100.0) ** 0.3\n",
        "        \n",
        "    for dim in range(0, min(rows * cols, target_dim)):\n",
        "        ax = axx[dim]\n",
        "\n",
        "        target[-3 * prediction_length :][dim].plot(ax=ax)\n",
        "        \n",
        "        ps_data = [forecast.quantile(p / 100.0)[:,dim] for p in percentiles_sorted]\n",
        "        i_p50 = len(percentiles_sorted) // 2\n",
        "        \n",
        "        p50_data = ps_data[i_p50]\n",
        "        p50_series = pd.Series(data=p50_data, index=forecast.index)\n",
        "        p50_series.plot(color=color, ls=\"-\", label=f\"{label_prefix}median\", ax=ax)\n",
        "        \n",
        "        for i in range(len(percentiles_sorted) // 2):\n",
        "            ptile = percentiles_sorted[i]\n",
        "            alpha = alpha_for_percentile(ptile)\n",
        "            ax.fill_between(\n",
        "                forecast.index,\n",
        "                ps_data[i],\n",
        "                ps_data[-i - 1],\n",
        "                facecolor=color,\n",
        "                alpha=alpha,\n",
        "                interpolate=True,\n",
        "            )\n",
        "        \n",
        "            pd.Series(data=p50_data[:1], index=forecast.index[:1]).plot(\n",
        "                color=color,\n",
        "                alpha=alpha,\n",
        "                linewidth=10,\n",
        "                label=f\"{label_prefix}{100 - ptile * 2}%\",\n",
        "                ax=ax,\n",
        "            )\n"
      ],
      "metadata": {
        "id": "8lycUlFkjTlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testons cette fonction sur les prédictions faites avec le modèle Vec-lstm-lowrank-Copula. Nous représentons 12 séries."
      ],
      "metadata": {
        "id": "LD6uy9Q1qaV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(targets[-1], forecasts[-1], prediction_length = prediction_length, prediction_intervals=(50.0, 90.0), color='g', fname=None)\n"
      ],
      "metadata": {
        "id": "CdRepoK_jg5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les prédictions faites ne sont pas satisfaisantes ici, pour deux raisons :\n",
        "* Les profils médians prédits ne suivent pas les profils journaliers de traffic observés, notamment les pics.\n",
        "* Les enveloppes de prédiction sont trop grandes ! Il ne nous est pas utile d'avoir ce type d'information.\n",
        "\n",
        "Nous allons tester le 3ème modèle, basé sur des processus gaussiens, pour constater si nous obtenons de meilleurs résultats."
      ],
      "metadata": {
        "id": "1O5TdkdHoRCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entraînement d'un modèle de prédiction GP-Copula"
      ],
      "metadata": {
        "id": "8FdOz_Czqw5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons passer à un dernier modèle : le *GP-Copula*. Ici encore,vous allez construire l'estimateur. Voici quelques indications :\n",
        "* Il s'agit d'un modèle GP : utilisez la classe *GPVAREstimator* (documentation : https://ts.gluon.ai/stable/api/gluonts/gluonts.mx.model.gpvar.html).\n",
        "* Vous devez préciser un nombre de séries à échantilloner dans chaque itération d'entraînement, prenez 5. \n",
        "* Précisez la transformation des données souhaitée, la même que pour le modèle Vec-lstm-lowrank-copula.\n",
        "* Utilisez une distribution de sortie adaptée. Ici nous souhaitons un processus gaussien avec matrice de faible rang en sortie. Cherchez la distribution adaptée dans la documentation : https://ts.gluon.ai/stable/api/gluonts/gluonts.mx.distribution.html. Choisissez un rang pour la matrice de covariance (une valeur petite, 5 par défaut, que vous devez là aussi préciser dans les arguments de la classe *GPVAREstimator*).\n",
        "* Enfin nous conserverons les mêmes valeurs d'hyperparamètres que dans les deux modèle précédents pour le réseau de neurone (lags, dropout, etc.). Nous gardons 10 epochs."
      ],
      "metadata": {
        "id": "VQNurC8nr5uR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Création d'un estimateur pour un modèle GP-copula\n",
        "estimator = GPVAREstimator(\n",
        "            target_dim=target_dim,\n",
        "            dropout_rate=0.01,\n",
        "            prediction_length=prediction_length,\n",
        "            cell_type=\"lstm\",\n",
        "            lags_seq = [1, 2, 12, 24],\n",
        "            scaling=False,\n",
        "            rank = 5,\n",
        "            target_dim_sample = 5,\n",
        "            freq=freq,\n",
        "            use_marginal_transformation=True,\n",
        "            distr_output=LowrankGPOutput(rank = 5, dim = target_dim),\n",
        "            trainer=Trainer(\n",
        "         epochs=10,\n",
        "         learning_rate=1e-3,\n",
        "         num_batches_per_epoch=10),\n",
        "        )\n",
        "\n",
        "#Entrainement sur la base d'apprentissage avec l'estimateur crée\n",
        "predictor = estimator.train(train_ds)\n"
      ],
      "metadata": {
        "id": "sceY5Wdxnrud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une fois votre modèle construit et entraîné, vous allez pouvoir lancer des prédictions sur la base de test."
      ],
      "metadata": {
        "id": "LtFq_VSH0Vb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prédictions sur fenêtres glissantes\n",
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "                test_ds, predictor=predictor, num_samples=30\n",
        "            )\n",
        "\n",
        "forecasts = list(forecast_it)\n",
        "targets = list(ts_it)\n",
        "\n",
        "# Evaluation\n",
        "agg_metric, item_metrics = evaluator(\n",
        "                    targets, forecasts, num_series=len(test_ds)\n",
        "                )\n",
        "\n",
        "print(\"CRPS: {}\".format(agg_metric['mean_wQuantileLoss']))\n",
        "print(\"MSE: {}\".format(agg_metric['MSE']))"
      ],
      "metadata": {
        "id": "uB_fa05C0UNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constatez vous une amélioration sur les métriques de test CRPS et MSE ? A votre avis pourquoi ? \n",
        "\n",
        "Visualisons quelques unes des prédictions faites avec ce nouveau modèle. "
      ],
      "metadata": {
        "id": "C-9fMMTA0k_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(targets[-1], forecasts[-1], prediction_length = prediction_length, prediction_intervals=(50.0, 90.0), color='g', fname=None)\n"
      ],
      "metadata": {
        "id": "vuMTRCMm1oQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les prédictions sont nettement plus proches de la réalité avec ce modèle.\n",
        "\n",
        "En pratique la recherche d'un bon modèle de prédiction n'est pas très différente de ce que nous avons vu dans cet atelier. Il s'agit d'alterner entre des phases d'entraînement et d'évaluation qui permettent de sélectionner :\n",
        "* Une bonne architecture pour le modèle de prédiction. Ici nous voyons un avantage du modèle GP sur les autres mais cela peut être différent selon les données que l'on étudie.\n",
        "* Un bon jeu d'hyperparamètres, à travers une grille de recherche. \n",
        "\n"
      ],
      "metadata": {
        "id": "Rm0G3qoG199_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pour terminer"
      ],
      "metadata": {
        "id": "z8p-78EC-msY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si vous avez terminé l'atelier à ce stade, je vous propose de tester un autre jeu de données, disponible avec la librairie GluonTS. *Solar* contient la production de 137 panneaux photovoltaïques dans l'état de l'Alabama. Ci-dessous, voici les codes nécessaires à l'importation des données depuis GluonTS et la création des objets itérables pour l'entraînement et l'évaluation. \n",
        "\n",
        "Utilisez ces données pour entraîner un modèle (GP-copula, Vec-lstm,...), l'évaluer et visualiser les prédictions. Vous pouvez modifier les hyperparamètres pour constater leur impact sur vos prédictions. Attention, des valeurs importantes de certains hyperparamètres peuvent entraîner des temps de calcul trop longs."
      ],
      "metadata": {
        "id": "am1QF2so3WaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fonctions nécessaires à l'importation de données accessibles avec GluonTS\n",
        "from gluonts.dataset.repository.datasets import get_dataset, dataset_recipes\n",
        "from gluonts.dataset.util import to_pandas\n",
        "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
        "\n",
        "#Sélection du dataset\n",
        "dataset = get_dataset(\"solar-energy\")\n",
        "target_dim=int(dataset.metadata.feat_static_cat[0].cardinality)\n",
        "freq=dataset.metadata.freq\n",
        "prediction_length = dataset.metadata.prediction_length\n",
        "  \n",
        "\n",
        "#Créations des bases d'entraînement et de test\n",
        "train_grouper = MultivariateGrouper(max_target_dim=target_dim)\n",
        "\n",
        "test_grouper = MultivariateGrouper(num_test_dates=int(len(dataset.test)/len(dataset.train)), \n",
        "                                   max_target_dim=target_dim)\n",
        "\n",
        "train_ds = train_grouper(dataset.train)\n",
        "test_ds = test_grouper(dataset.test)"
      ],
      "metadata": {
        "id": "08ycVpQa3yep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les bases d'entraînement et de test sont créees. Vous pouvez faire apprendre ces données à un nouveau modèle."
      ],
      "metadata": {
        "id": "arMJoCcy-IHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Estimation et prédictions pour le modèle ... appliqué aux données Solar\n",
        "\n",
        "estimator = ...\n",
        "predictor = ..."
      ],
      "metadata": {
        "id": "L9eKZsQr-Wny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merci d'avoir suivi cet atelier ! "
      ],
      "metadata": {
        "id": "by4hsjNF-x_H"
      }
    }
  ]
}